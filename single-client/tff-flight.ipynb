{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow-federated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = os.path.join('..', 'dataset', 'processed')\n",
    "flight_icao_num = 'a007c6'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    dfs = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            dfs.append(df)\n",
    "\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    columns_to_drop = ['signature_label', 'icao24', 'Unnamed: 0']\n",
    "\n",
    "    y = combined_df['signature_label']\n",
    "    X = combined_df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(X, y, trip_numbers: list):\n",
    "    X_train = pd.DataFrame()\n",
    "    X_test = pd.DataFrame()\n",
    "\n",
    "    all_files = os.listdir(folder_path)\n",
    "\n",
    "    files_not_in_trip_numbers = [file for file in all_files if not any((flight_icao_num + \"_\" + str(trip) + \".csv\") in file for trip in trip_numbers)]\n",
    "    files_in_trip_numbers = [file for file in all_files if any((flight_icao_num + \"_\" + str(trip) + \".csv\") in file for trip in trip_numbers)]\n",
    "\n",
    "    print(files_in_trip_numbers)\n",
    "\n",
    "    for train_data_file in files_in_trip_numbers:\n",
    "        file_path = os.path.join(folder_path, train_data_file)\n",
    "        \n",
    "        print(\"TRAIN\", file_path)\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "        X_train = pd.concat([X_train, df], ignore_index=True)\n",
    "\n",
    "    for test_data_file in files_not_in_trip_numbers:\n",
    "        file_path = os.path.join(folder_path, test_data_file)\n",
    "        \n",
    "        print(\"TEST\", file_path)\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "        X_test = pd.concat([X_test, df], ignore_index=True)\n",
    "\n",
    "    drop_columns = ['Unnamed: 0', 'icao24', 'trip_number']\n",
    "    X_train = X_train.drop(drop_columns, axis=1)\n",
    "    X_test = X_test.drop(drop_columns, axis=1)\n",
    "\n",
    "    y_train = X_train['signature_label']\n",
    "    X_train = X_train.drop('signature_label', axis=1)\n",
    "\n",
    "    y_test = X_test['signature_label']\n",
    "    X_test = X_test.drop('signature_label', axis=1)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_scaling(input_X):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    scaled_value = scaler.fit_transform(input_X)\n",
    "    return scaled_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting to Tensors Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensors(input_features, labels):\n",
    "    X_inputs = tf.convert_to_tensor(input_features, name=\"flights-inputs\")\n",
    "    y_labels = tf.convert_to_tensor(labels, name=\"flights-labels\")\n",
    "\n",
    "    return X_inputs, y_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Fed Learning Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fed_dataset(train, test):\n",
    "    client_data = {}\n",
    "\n",
    "    client_data[f\"f_1\"] = train\n",
    "    client_data[f\"f_2\"] = test\n",
    "\n",
    "    # client_ids = list(client_data.keys())\n",
    "\n",
    "    client_data_values = []\n",
    "\n",
    "    for key, value in client_data.items():\n",
    "        client_data_values.append(value)\n",
    "\n",
    "    return client_data_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(4, )),\n",
    "        tf.keras.layers.Dense(10, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    return tff.learning.from_keras_model(\n",
    "      model,\n",
    "      input_spec=input_spec_value,\n",
    "      loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "      metrics=[tf.keras.metrics.Accuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = read_data()\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test_split(X, y, trip_numbers=[0,1])\n",
    "\n",
    "X_train_scaled = perform_scaling(X_train)\n",
    "X_test_scaled = perform_scaling(X_test)\n",
    "\n",
    "X_train_raw = np.asarray(X_train_scaled).astype(np.float32)[:, np.newaxis]\n",
    "y_train_label = np.asarray(y_train).astype(np.int32).reshape(X_train_scaled.shape[0], 1)\n",
    "\n",
    "X_test_raw = np.asarray(X_test_scaled).astype(np.float32)[:, np.newaxis]\n",
    "y_test_label = np.asarray(y_test).astype(np.int32).reshape(X_test_scaled.shape[0], 1)\n",
    "\n",
    "X_train_features, y_train_labels = convert_to_tensors(X_train_raw, y_train_label)\n",
    "X_test_features, y_test_labels = convert_to_tensors(X_test_raw, y_test_label)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train_features, y_train_labels))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test_features, y_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_spec_value = train_ds.element_spec\n",
    "\n",
    "federated_train_data = create_fed_dataset(train_ds, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.1))\n",
    "\n",
    "# trainer = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "#      model_fn,\n",
    "#      client_optimizer_fn=lambda: tf.keras.optimizers.SGD(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_process.initialize.type_signature.formatted_representation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_state = training_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ROUNDS = 11\n",
    "\n",
    "tff_train_acc = []\n",
    "tff_train_loss = []\n",
    "tff_val_acc = []\n",
    "tff_val_loss = []\n",
    "\n",
    "for i in range(NUM_ROUNDS):\n",
    "  # Train\n",
    "  result = trainer.next(train_state, federated_train_data)\n",
    "  state = result.state\n",
    "  train_metrics = result.metrics['client_work']['train']\n",
    "  print('round {:2d}, metrics={}'.format(i, train_metrics))\n",
    "\n",
    "\n",
    "  # # Validation\n",
    "  # federated_metrics = tff.learning.algorithms.build_fed_eval(result.state.global_model_weights(), val_data)\n",
    "  # val_metrics = federated_metrics['eval']\n",
    "\n",
    "  # # Metrics\n",
    "  # train_loss = train_metrics['loss']\n",
    "  # train_acc = train_metrics['binary_crossentropy']\n",
    "  # val_loss = val_metrics['loss']\n",
    "  # val_acc = val_metrics['accuracy']\n",
    "\n",
    "  # # Print\n",
    "  # print('round {:2d}\\ntrain_loss={l:.3f}, train_acc={ac:.3f}'.format(\n",
    "  #     i+1, l=train_loss, ac=train_metrics['binary_crossentropy']))\n",
    "  # print('val_loss: {:.3f} val_acc: {:.3f}'.format(\n",
    "  #     val_loss, val_acc))\n",
    "\n",
    "  # # logs\n",
    "  # tff_train_acc.append(float(train_metrics['binary_crossentropy']))\n",
    "  # tff_train_loss.append(float(train_metrics['loss']))\n",
    "  # tff_val_acc.append(float(val_metrics['binary_crossentropy']))\n",
    "  # tff_val_loss.append(float(val_metrics['loss']))\n",
    "  # current_round = i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
